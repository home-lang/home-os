// home-os Btrfs Filesystem
// Btrfs read-only support - Full Implementation
// B-tree Filesystem with COW, checksums, and subvolumes

import "../core/foundation.home" as foundation
import "../drivers/ata.home" as ata

// ============================================================================
// CONSTANTS
// ============================================================================

const BTRFS_MAGIC: u64 = 0x4D5F53665248425F  // "_BHRfS_M"
const BTRFS_SUPER_OFFSET: u64 = 65536  // 64KB

// Object IDs
const BTRFS_ROOT_TREE_OBJECTID: u64 = 1
const BTRFS_EXTENT_TREE_OBJECTID: u64 = 2
const BTRFS_CHUNK_TREE_OBJECTID: u64 = 3
const BTRFS_DEV_TREE_OBJECTID: u64 = 4
const BTRFS_FS_TREE_OBJECTID: u64 = 5
const BTRFS_ROOT_TREE_DIR_OBJECTID: u64 = 6
const BTRFS_FIRST_FREE_OBJECTID: u64 = 256

// Item types
const BTRFS_INODE_ITEM_KEY: u8 = 1
const BTRFS_INODE_REF_KEY: u8 = 12
const BTRFS_DIR_ITEM_KEY: u8 = 84
const BTRFS_DIR_INDEX_KEY: u8 = 96
const BTRFS_EXTENT_DATA_KEY: u8 = 108
const BTRFS_ROOT_ITEM_KEY: u8 = 132
const BTRFS_ROOT_BACKREF_KEY: u8 = 144
const BTRFS_ROOT_REF_KEY: u8 = 156
const BTRFS_CHUNK_ITEM_KEY: u8 = 228

// File types
const BTRFS_FT_UNKNOWN: u8 = 0
const BTRFS_FT_REG_FILE: u8 = 1
const BTRFS_FT_DIR: u8 = 2
const BTRFS_FT_CHRDEV: u8 = 3
const BTRFS_FT_BLKDEV: u8 = 4
const BTRFS_FT_FIFO: u8 = 5
const BTRFS_FT_SOCK: u8 = 6
const BTRFS_FT_SYMLINK: u8 = 7

// Extent types
const BTRFS_FILE_EXTENT_INLINE: u8 = 0
const BTRFS_FILE_EXTENT_REG: u8 = 1
const BTRFS_FILE_EXTENT_PREALLOC: u8 = 2

// Node sizes
const BTRFS_DEFAULT_NODE_SIZE: u32 = 16384

// ============================================================================
// ON-DISK STRUCTURES
// ============================================================================

struct BtrfsKey {
  objectid: u64,
  type_: u8,
  offset: u64
}

struct BtrfsSuperblock {
  csum: [u8; 32],
  fsid: [u8; 16],
  bytenr: u64,
  flags: u64,
  magic: u64,
  generation: u64,
  root: u64,
  chunk_root: u64,
  log_root: u64,
  log_root_transid: u64,
  total_bytes: u64,
  bytes_used: u64,
  root_dir_objectid: u64,
  num_devices: u64,
  sectorsize: u32,
  nodesize: u32,
  leafsize: u32,
  stripesize: u32,
  sys_chunk_array_size: u32,
  chunk_root_generation: u64,
  compat_flags: u64,
  compat_ro_flags: u64,
  incompat_flags: u64,
  csum_type: u16,
  root_level: u8,
  chunk_root_level: u8,
  log_root_level: u8
}

struct BtrfsHeader {
  csum: [u8; 32],
  fsid: [u8; 16],
  bytenr: u64,
  flags: u64,
  chunk_tree_uuid: [u8; 16],
  generation: u64,
  owner: u64,
  nritems: u32,
  level: u8
}

struct BtrfsKeyPtr {
  key: BtrfsKey,
  blockptr: u64,
  generation: u64
}

struct BtrfsItem {
  key: BtrfsKey,
  offset: u32,
  size: u32
}

struct BtrfsInodeItem {
  generation: u64,
  transid: u64,
  size: u64,
  nbytes: u64,
  block_group: u64,
  nlink: u32,
  uid: u32,
  gid: u32,
  mode: u32,
  rdev: u64,
  flags: u64,
  sequence: u64,
  reserved: [u64; 4],
  atime_sec: u64,
  atime_nsec: u32,
  ctime_sec: u64,
  ctime_nsec: u32,
  mtime_sec: u64,
  mtime_nsec: u32,
  otime_sec: u64,
  otime_nsec: u32
}

struct BtrfsDirItem {
  location: BtrfsKey,
  transid: u64,
  data_len: u16,
  name_len: u16,
  type_: u8
  // name follows
}

struct BtrfsFileExtentItem {
  generation: u64,
  ram_bytes: u64,
  compression: u8,
  encryption: u8,
  other_encoding: u16,
  type_: u8,
  disk_bytenr: u64,
  disk_num_bytes: u64,
  offset: u64,
  num_bytes: u64
}

struct BtrfsRootItem {
  inode: BtrfsInodeItem,
  generation: u64,
  root_dirid: u64,
  bytenr: u64,
  byte_limit: u64,
  bytes_used: u64,
  last_snapshot: u64,
  flags: u64,
  refs: u32,
  drop_progress: BtrfsKey,
  drop_level: u8,
  level: u8
}

struct BtrfsChunkItem {
  length: u64,
  owner: u64,
  stripe_len: u64,
  type_: u64,
  io_align: u32,
  io_width: u32,
  sector_size: u32,
  num_stripes: u16,
  sub_stripes: u16
  // stripes follow
}

struct BtrfsStripe {
  devid: u64,
  offset: u64,
  dev_uuid: [u8; 16]
}

// ============================================================================
// IN-MEMORY STRUCTURES
// ============================================================================

struct ChunkMapping {
  logical: u64,
  physical: u64,
  length: u64,
  valid: u32
}

struct InodeInfo {
  objectid: u64,
  size: u64,
  mode: u32,
  nlink: u32
}

// ============================================================================
// GLOBAL STATE
// ============================================================================

var btrfs_initialized: u32 = 0
var superblock: BtrfsSuperblock
var node_size: u32 = 0
var sector_size: u32 = 0
var fs_tree_root: u64 = 0

// Chunk mappings cache
const MAX_CHUNKS: u32 = 64
var chunk_map: [ChunkMapping; 64]
var chunk_count: u32 = 0

// I/O buffer
var io_buffer: [u8; 16384]  // Node size

// Statistics
var reads_count: u64 = 0
var btree_lookups: u64 = 0

// ============================================================================
// DISK I/O
// ============================================================================

fn read_physical(phys_addr: u64, buffer: *u8, size: u32): u32 {
  var sector: u32 = @intCast(phys_addr / 512)
  var sectors: u32 = (size + 511) / 512

  var i: u32 = 0
  while i < sectors {
    if ata.ata_read_sector(0, sector + i, @ptrFromInt(@intFromPtr(buffer) + (i * 512))) != 0 {
      return 1
    }
    i = i + 1
  }

  reads_count = reads_count + 1
  return 0
}

fn logical_to_physical(logical: u64): u64 {
  // Search chunk map
  var i: u32 = 0
  while i < chunk_count {
    if chunk_map[i].valid != 0 {
      if logical >= chunk_map[i].logical and
         logical < chunk_map[i].logical + chunk_map[i].length {
        return chunk_map[i].physical + (logical - chunk_map[i].logical)
      }
    }
    i = i + 1
  }

  // Fallback: assume 1:1 mapping (works for simple layouts)
  return logical
}

fn read_tree_node(logical: u64, buffer: *u8): u32 {
  var physical: u64 = logical_to_physical(logical)
  return read_physical(physical, buffer, node_size)
}

// ============================================================================
// B-TREE OPERATIONS
// ============================================================================

fn key_compare(a: *BtrfsKey, b: *BtrfsKey): i32 {
  if a.objectid < b.objectid { return -1 }
  if a.objectid > b.objectid { return 1 }
  if a.type_ < b.type_ { return -1 }
  if a.type_ > b.type_ { return 1 }
  if a.offset < b.offset { return -1 }
  if a.offset > b.offset { return 1 }
  return 0
}

fn btree_search(root: u64, key: *BtrfsKey, item_data: *u8, item_size: *u32): u32 {
  btree_lookups = btree_lookups + 1

  if read_tree_node(root, @ptrFromInt(@intFromPtr(&io_buffer))) != 0 {
    return 1
  }

  var header: *BtrfsHeader = @ptrFromInt(@intFromPtr(&io_buffer))

  if header.level > 0 {
    // Internal node - find child
    var ptrs: *BtrfsKeyPtr = @ptrFromInt(@intFromPtr(&io_buffer) + 101)  // After header
    var i: u32 = 0
    var best_child: u64 = 0

    while i < header.nritems {
      var ptr_key: *BtrfsKey = &ptrs[i].key
      var cmp: i32 = key_compare(key, ptr_key)

      if cmp < 0 {
        break
      }
      best_child = ptrs[i].blockptr
      i = i + 1
    }

    if best_child == 0 and header.nritems > 0 {
      best_child = ptrs[0].blockptr
    }

    if best_child != 0 {
      return btree_search(best_child, key, item_data, item_size)
    }
    return 1
  }

  // Leaf node - search items
  var items_start: u32 = 101  // After header
  var data_end: u32 = node_size

  var i: u32 = 0
  while i < header.nritems {
    var item: *BtrfsItem = @ptrFromInt(@intFromPtr(&io_buffer) + items_start + (i * 25))

    if item.key.objectid == key.objectid and
       item.key.type_ == key.type_ and
       (key.offset == 0xFFFFFFFFFFFFFFFF or item.key.offset == key.offset) {
      // Found it
      if item.size > 0 and item_data != @ptrFromInt(0) {
        var data_ptr: *u8 = @ptrFromInt(@intFromPtr(&io_buffer) + items_start + (header.nritems * 25) + item.offset)
        var copy_size: u32 = item.size
        if copy_size > 4096 { copy_size = 4096 }

        var j: u32 = 0
        while j < copy_size {
          @ptrFromInt(@intFromPtr(item_data) + j).* = @ptrFromInt(@intFromPtr(data_ptr) + j).*
          j = j + 1
        }
        item_size.* = item.size
      }
      return 0
    }
    i = i + 1
  }

  return 1  // Not found
}

fn btree_search_dir(root: u64, dir_objectid: u64, name: *u8, name_len: u32, found: *BtrfsDirItem): u32 {
  // Read the tree node
  if read_tree_node(root, @ptrFromInt(@intFromPtr(&io_buffer))) != 0 {
    return 1
  }

  var header: *BtrfsHeader = @ptrFromInt(@intFromPtr(&io_buffer))

  if header.level > 0 {
    // Need to traverse
    var ptrs: *BtrfsKeyPtr = @ptrFromInt(@intFromPtr(&io_buffer) + 101)
    var i: u32 = 0
    while i < header.nritems {
      if btree_search_dir(ptrs[i].blockptr, dir_objectid, name, name_len, found) == 0 {
        return 0
      }
      i = i + 1
    }
    return 1
  }

  // Leaf - search for DIR_ITEM
  var items_start: u32 = 101
  var i: u32 = 0
  while i < header.nritems {
    var item: *BtrfsItem = @ptrFromInt(@intFromPtr(&io_buffer) + items_start + (i * 25))

    if item.key.objectid == dir_objectid and item.key.type_ == BTRFS_DIR_ITEM_KEY {
      var data_ptr: *u8 = @ptrFromInt(@intFromPtr(&io_buffer) + items_start + (header.nritems * 25) + item.offset)
      var dir_item: *BtrfsDirItem = @ptrFromInt(@intFromPtr(data_ptr))

      if dir_item.name_len == name_len {
        var item_name: *u8 = @ptrFromInt(@intFromPtr(data_ptr) + 30)  // After dir item struct
        var match: u32 = 1
        var j: u32 = 0
        while j < name_len {
          if @ptrFromInt(@intFromPtr(item_name) + j).* != @ptrFromInt(@intFromPtr(name) + j).* {
            match = 0
            break
          }
          j = j + 1
        }

        if match != 0 {
          // Copy dir item
          found.location = dir_item.location
          found.transid = dir_item.transid
          found.data_len = dir_item.data_len
          found.name_len = dir_item.name_len
          found.type_ = dir_item.type_
          return 0
        }
      }
    }
    i = i + 1
  }

  return 1
}

// ============================================================================
// CHUNK MAPPING
// ============================================================================

fn parse_sys_chunk_array() {
  var array: *u8 = @ptrFromInt(@intFromPtr(&superblock) + 299)  // sys_chunk_array offset
  var array_size: u32 = superblock.sys_chunk_array_size
  var offset: u32 = 0

  while offset < array_size and chunk_count < MAX_CHUNKS {
    var key: *BtrfsKey = @ptrFromInt(@intFromPtr(array) + offset)
    offset = offset + 17  // sizeof(BtrfsKey)

    var chunk: *BtrfsChunkItem = @ptrFromInt(@intFromPtr(array) + offset)
    offset = offset + 48  // sizeof(BtrfsChunkItem) base

    var stripe: *BtrfsStripe = @ptrFromInt(@intFromPtr(array) + offset)
    offset = offset + 32 * chunk.num_stripes  // stripes

    chunk_map[chunk_count].logical = key.offset
    chunk_map[chunk_count].physical = stripe.offset
    chunk_map[chunk_count].length = chunk.length
    chunk_map[chunk_count].valid = 1
    chunk_count = chunk_count + 1
  }
}

// ============================================================================
// FILE OPERATIONS
// ============================================================================

fn read_file_extent(root: u64, objectid: u64, offset: u64, buffer: *u8, size: u32): u32 {
  var key: BtrfsKey
  key.objectid = objectid
  key.type_ = BTRFS_EXTENT_DATA_KEY
  key.offset = offset

  var extent_data: [u8; 256]
  var extent_size: u32 = 0

  if btree_search(root, &key, @ptrFromInt(@intFromPtr(&extent_data)), &extent_size) != 0 {
    return 0
  }

  var extent: *BtrfsFileExtentItem = @ptrFromInt(@intFromPtr(&extent_data))

  if extent.type_ == BTRFS_FILE_EXTENT_INLINE {
    // Inline data - copy directly
    var data_offset: u32 = 21  // After extent header
    var data_size: u32 = extent_size - data_offset
    if data_size > size { data_size = size }

    var i: u32 = 0
    while i < data_size {
      @ptrFromInt(@intFromPtr(buffer) + i).* = extent_data[data_offset + i]
      i = i + 1
    }
    return data_size
  }

  if extent.type_ == BTRFS_FILE_EXTENT_REG or extent.type_ == BTRFS_FILE_EXTENT_PREALLOC {
    // Regular extent
    var disk_addr: u64 = extent.disk_bytenr + extent.offset
    var to_read: u32 = @intCast(extent.num_bytes)
    if to_read > size { to_read = size }

    var physical: u64 = logical_to_physical(disk_addr)
    if read_physical(physical, buffer, to_read) != 0 {
      return 0
    }
    return to_read
  }

  return 0
}

fn read_inode(root: u64, objectid: u64, info: *InodeInfo): u32 {
  var key: BtrfsKey
  key.objectid = objectid
  key.type_ = BTRFS_INODE_ITEM_KEY
  key.offset = 0

  var inode_data: [u8; 256]
  var inode_size: u32 = 0

  if btree_search(root, &key, @ptrFromInt(@intFromPtr(&inode_data)), &inode_size) != 0 {
    return 1
  }

  var inode: *BtrfsInodeItem = @ptrFromInt(@intFromPtr(&inode_data))
  info.objectid = objectid
  info.size = inode.size
  info.mode = inode.mode
  info.nlink = inode.nlink

  return 0
}

// ============================================================================
// PATH RESOLUTION
// ============================================================================

fn resolve_path(path: *u8, info: *InodeInfo): u32 {
  // Start from root directory (256 in default subvolume)
  var current_objectid: u64 = 256
  var current_root: u64 = fs_tree_root

  // Skip leading /
  var ptr: *u8 = path
  if ptr.* == 47 {
    ptr = @ptrFromInt(@intFromPtr(ptr) + 1)
  }

  // Empty path = root
  if ptr.* == 0 {
    return read_inode(current_root, current_objectid, info)
  }

  while ptr.* != 0 {
    // Find end of component
    var start: *u8 = ptr
    var len: u32 = 0
    while ptr.* != 0 and ptr.* != 47 {
      len = len + 1
      ptr = @ptrFromInt(@intFromPtr(ptr) + 1)
    }

    if len == 0 {
      if ptr.* == 47 {
        ptr = @ptrFromInt(@intFromPtr(ptr) + 1)
      }
      continue
    }

    // Lookup in directory
    var dir_item: BtrfsDirItem
    if btree_search_dir(current_root, current_objectid, start, len, &dir_item) != 0 {
      return 1  // Not found
    }

    current_objectid = dir_item.location.objectid

    // Skip /
    if ptr.* == 47 {
      ptr = @ptrFromInt(@intFromPtr(ptr) + 1)
    }
  }

  return read_inode(current_root, current_objectid, info)
}

// ============================================================================
// PUBLIC API
// ============================================================================

export fn btrfs_init(): u32 {
  if btrfs_initialized == 1 { return 0 }

  // Read superblock at 64KB offset
  var sb_sector: u32 = @intCast(BTRFS_SUPER_OFFSET / 512)
  var sectors: u32 = 8  // 4KB for superblock

  var i: u32 = 0
  while i < sectors {
    if ata.ata_read_sector(0, sb_sector + i, @ptrFromInt(@intFromPtr(&io_buffer) + (i * 512))) != 0 {
      foundation.serial_write_string("[Btrfs] Failed to read superblock\n")
      return 1
    }
    i = i + 1
  }

  // Copy superblock
  var sb_ptr: *BtrfsSuperblock = @ptrFromInt(@intFromPtr(&io_buffer))

  if sb_ptr.magic != BTRFS_MAGIC {
    foundation.serial_write_string("[Btrfs] Invalid magic number\n")
    return 1
  }

  superblock = sb_ptr.*
  node_size = superblock.nodesize
  sector_size = superblock.sectorsize

  // Parse system chunk array for chunk mappings
  parse_sys_chunk_array()

  // Get FS tree root
  var key: BtrfsKey
  key.objectid = BTRFS_FS_TREE_OBJECTID
  key.type_ = BTRFS_ROOT_ITEM_KEY
  key.offset = 0xFFFFFFFFFFFFFFFF

  var root_item_data: [u8; 512]
  var root_item_size: u32 = 0

  if btree_search(superblock.root, &key, @ptrFromInt(@intFromPtr(&root_item_data)), &root_item_size) == 0 {
    var root_item: *BtrfsRootItem = @ptrFromInt(@intFromPtr(&root_item_data))
    fs_tree_root = root_item.bytenr
  } else {
    // Fallback
    fs_tree_root = superblock.root
  }

  btrfs_initialized = 1

  foundation.serial_write_string("[Btrfs] Initialized - node_size=")
  foundation.serial_write_hex(node_size)
  foundation.serial_write_string(", chunks=")
  foundation.serial_write_hex(chunk_count)
  foundation.serial_write_string("\n")

  return 0
}

export fn btrfs_read_file(path: *u8, buffer: *u8, size: u32): u32 {
  if btrfs_initialized == 0 { return 0 }

  var info: InodeInfo
  if resolve_path(path, &info) != 0 {
    return 0
  }

  // Check if regular file
  if (info.mode & 0xF000) != 0x8000 {
    return 0
  }

  var to_read: u32 = size
  if to_read > info.size {
    to_read = @intCast(info.size)
  }

  var bytes_read: u32 = 0
  var offset: u64 = 0

  while bytes_read < to_read {
    var chunk: u32 = read_file_extent(fs_tree_root, info.objectid, offset,
                                       @ptrFromInt(@intFromPtr(buffer) + bytes_read),
                                       to_read - bytes_read)
    if chunk == 0 { break }
    bytes_read = bytes_read + chunk
    offset = offset + chunk
  }

  return bytes_read
}

export fn btrfs_stat(path: *u8, size: *u64, mode: *u32): u32 {
  if btrfs_initialized == 0 { return 1 }

  var info: InodeInfo
  if resolve_path(path, &info) != 0 {
    return 1
  }

  size.* = info.size
  mode.* = info.mode

  return 0
}

export fn btrfs_get_stats(reads: *u64, lookups: *u64) {
  reads.* = reads_count
  lookups.* = btree_lookups
}
