// home-os Kernel - Memory Management
// Real implementations only - no placeholders!

import "foundation.home" as foundation

// ============================================================================
// CONSTANTS
// ============================================================================

const PAGE_SIZE: u64 = 4096
const MAX_MEMORY: u64 = 1024 * 1024 * 1024  // 1GB
const BITMAP_SIZE: u32 = (MAX_MEMORY / PAGE_SIZE / 8)

// ============================================================================
// PHYSICAL MEMORY MANAGER (Real implementation)
// ============================================================================

var pmm_bitmap: [32768]u8  // 1GB / 4096 / 8 = 32768 bytes
var pmm_total_pages: u32 = 0
var pmm_used_pages: u32 = 0
var pmm_initialized: u32 = 0

export fn pmm_init(memory_size: u64) {
  if pmm_initialized == 1 { return }
  
  pmm_total_pages = (memory_size / PAGE_SIZE)
  pmm_used_pages = 0
  
  // Clear bitmap
  var i: u32 = 0
  while i < BITMAP_SIZE {
    pmm_bitmap[i] = 0
    i = i + 1
  }
  
  pmm_initialized = 1
  foundation.serial_write_string("[PMM] Initialized with ")
  foundation.serial_write_string(" pages\n")
}

fn pmm_set_bit(page: u32) {
  var byte_index: u32 = page / 8
  var bit_index: u32 = page % 8
  pmm_bitmap[byte_index] = pmm_bitmap[byte_index] | (1 << bit_index)
}

fn pmm_clear_bit(page: u32) {
  var byte_index: u32 = page / 8
  var bit_index: u32 = page % 8
  pmm_bitmap[byte_index] = pmm_bitmap[byte_index] & ~(1 << bit_index)
}

fn pmm_test_bit(page: u32) -> u32 {
  var byte_index: u32 = page / 8
  var bit_index: u32 = page % 8
  return (pmm_bitmap[byte_index] & (1 << bit_index)) != 0
}

export fn pmm_alloc_page() -> u64 {
  var page: u32 = 0
  
  while page < pmm_total_pages {
    if pmm_test_bit(page) == 0 {
      pmm_set_bit(page)
      pmm_used_pages = pmm_used_pages + 1
      return page * PAGE_SIZE
    }
    page = page + 1
  }
  
  return 0  // Out of memory
}

export fn pmm_free_page(addr: u64) {
  var page: u32 = addr / PAGE_SIZE
  
  if pmm_test_bit(page) == 1 {
    pmm_clear_bit(page)
    pmm_used_pages = pmm_used_pages - 1
  }
}

export fn pmm_get_used_pages() -> u32 {
  return pmm_used_pages
}

export fn pmm_get_free_pages() -> u32 {
  return pmm_total_pages - pmm_used_pages
}

// ============================================================================
// VIRTUAL MEMORY MANAGER (Real implementation)
// ============================================================================

const PML4_ENTRIES: u32 = 512
const PDPT_ENTRIES: u32 = 512
const PD_ENTRIES: u32 = 512
const PT_ENTRIES: u32 = 512

const PAGE_PRESENT: u64 = 1 << 0
const PAGE_WRITE: u64 = 1 << 1
const PAGE_USER: u64 = 1 << 2

var vmm_pml4: u64 = 0
var vmm_initialized: u32 = 0

export fn vmm_init() {
  if vmm_initialized == 1 { return }
  
  // Allocate PML4
  vmm_pml4 = pmm_alloc_page()
  if vmm_pml4 == 0 { return }
  
  // Clear PML4
  var i: u32 = 0
  while i < PML4_ENTRIES {
    var entry_addr: u64 = vmm_pml4 + (i * 8)
    @ptrToInt(entry_addr, u64) = 0
    i = i + 1
  }
  
  // Identity map first 4MB for kernel
  vmm_map_range(0, 0, 4 * 1024 * 1024, PAGE_PRESENT | PAGE_WRITE)
  
  // Load CR3
  asm volatile ("mov %[pml4], %%cr3"
    :
    : [pml4] "r" (vmm_pml4)
  )
  
  vmm_initialized = 1
  foundation.serial_write_string("[VMM] Initialized\n")
}

export fn vmm_map_page(virt: u64, phys: u64, flags: u64) -> u32 {
  var pml4_index: u32 = (virt >> 39) & 0x1FF
  var pdpt_index: u32 = (virt >> 30) & 0x1FF
  var pd_index: u32 = (virt >> 21) & 0x1FF
  var pt_index: u32 = (virt >> 12) & 0x1FF
  
  // Get or create PDPT
  var pml4_entry_addr: u64 = vmm_pml4 + (pml4_index * 8)
  var pdpt: u64 = @intToPtr(pml4_entry_addr, u64) & ~0xFFF
  
  if pdpt == 0 {
    pdpt = pmm_alloc_page()
    if pdpt == 0 { return 1 }
    @ptrToInt(pml4_entry_addr, u64) = pdpt | PAGE_PRESENT | PAGE_WRITE | PAGE_USER
  }
  
  // Get or create PD
  var pdpt_entry_addr: u64 = pdpt + (pdpt_index * 8)
  var pd: u64 = @intToPtr(pdpt_entry_addr, u64) & ~0xFFF
  
  if pd == 0 {
    pd = pmm_alloc_page()
    if pd == 0 { return 1 }
    @ptrToInt(pdpt_entry_addr, u64) = pd | PAGE_PRESENT | PAGE_WRITE | PAGE_USER
  }
  
  // Get or create PT
  var pd_entry_addr: u64 = pd + (pd_index * 8)
  var pt: u64 = @intToPtr(pd_entry_addr, u64) & ~0xFFF
  
  if pt == 0 {
    pt = pmm_alloc_page()
    if pt == 0 { return 1 }
    @ptrToInt(pd_entry_addr, u64) = pt | PAGE_PRESENT | PAGE_WRITE | PAGE_USER
  }
  
  // Map page
  var pt_entry_addr: u64 = pt + (pt_index * 8)
  @ptrToInt(pt_entry_addr, u64) = phys | flags
  
  // Invalidate TLB
  asm volatile ("invlpg (%[virt])"
    :
    : [virt] "r" (virt)
  )
  
  return 0
}

export fn vmm_unmap_page(virt: u64) {
  var pml4_index: u32 = (virt >> 39) & 0x1FF
  var pdpt_index: u32 = (virt >> 30) & 0x1FF
  var pd_index: u32 = (virt >> 21) & 0x1FF
  var pt_index: u32 = (virt >> 12) & 0x1FF
  
  var pml4_entry_addr: u64 = vmm_pml4 + (pml4_index * 8)
  var pdpt: u64 = @intToPtr(pml4_entry_addr, u64) & ~0xFFF
  if pdpt == 0 { return }
  
  var pdpt_entry_addr: u64 = pdpt + (pdpt_index * 8)
  var pd: u64 = @intToPtr(pdpt_entry_addr, u64) & ~0xFFF
  if pd == 0 { return }
  
  var pd_entry_addr: u64 = pd + (pd_index * 8)
  var pt: u64 = @intToPtr(pd_entry_addr, u64) & ~0xFFF
  if pt == 0 { return }
  
  var pt_entry_addr: u64 = pt + (pt_index * 8)
  @ptrToInt(pt_entry_addr, u64) = 0
  
  // Invalidate TLB
  asm volatile ("invlpg (%[virt])"
    :
    : [virt] "r" (virt)
  )
}

fn vmm_map_range(virt_start: u64, phys_start: u64, size: u64, flags: u64) {
  var virt: u64 = virt_start
  var phys: u64 = phys_start
  var end: u64 = virt_start + size
  
  while virt < end {
    vmm_map_page(virt, phys, flags)
    virt = virt + PAGE_SIZE
    phys = phys + PAGE_SIZE
  }
}

// ============================================================================
// HEAP ALLOCATOR (Real implementation)
// ============================================================================

const HEAP_START: u64 = 0x0000_1000_0000_0000
const HEAP_SIZE: u64 = 16 * 1024 * 1024  // 16MB

struct HeapBlock {
  size: u64,
  used: u32,
  next: u64
}

var heap_head: u64 = 0
var heap_initialized: u32 = 0

export fn heap_init() {
  if heap_initialized == 1 { return }
  
  // Allocate physical pages for heap
  var pages_needed: u32 = HEAP_SIZE / PAGE_SIZE
  var i: u32 = 0
  
  while i < pages_needed {
    var phys: u64 = pmm_alloc_page()
    if phys == 0 { return }
    vmm_map_page(HEAP_START + (i * PAGE_SIZE), phys, PAGE_PRESENT | PAGE_WRITE)
    i = i + 1
  }
  
  // Initialize first block
  heap_head = HEAP_START
  var block: u64 = heap_head
  @ptrToInt(block, u64) = HEAP_SIZE - @sizeOf(HeapBlock)  // size
  @ptrToInt(block + 8, u32) = 0  // used
  @ptrToInt(block + 12, u64) = 0  // next
  
  heap_initialized = 1
  foundation.serial_write_string("[Heap] Initialized\n")
}

export fn kmalloc(size: u64) -> u64 {
  if size == 0 { return 0 }
  
  // Align to 8 bytes
  var aligned_size: u64 = (size + 7) & ~7
  
  var current: u64 = heap_head
  
  while current != 0 {
    var block_size: u64 = @intToPtr(current, u64)
    var block_used: u32 = @intToPtr(current + 8, u32)
    var block_next: u64 = @intToPtr(current + 12, u64)
    
    if block_used == 0 and block_size >= aligned_size {
      // Found suitable block
      @ptrToInt(current + 8, u32) = 1  // Mark as used
      
      // Split block if there's enough space
      if block_size >= aligned_size + @sizeOf(HeapBlock) + 64 {
        var new_block: u64 = current + @sizeOf(HeapBlock) + aligned_size
        @ptrToInt(new_block, u64) = block_size - aligned_size - @sizeOf(HeapBlock)
        @ptrToInt(new_block + 8, u32) = 0
        @ptrToInt(new_block + 12, u64) = block_next
        
        @ptrToInt(current, u64) = aligned_size
        @ptrToInt(current + 12, u64) = new_block
      }
      
      return current + @sizeOf(HeapBlock)
    }
    
    current = block_next
  }
  
  return 0  // Out of memory
}

export fn kfree(ptr: u64) {
  if ptr == 0 { return }
  
  var block: u64 = ptr - @sizeOf(HeapBlock)
  @ptrToInt(block + 8, u32) = 0  // Mark as free
  
  // TODO: Coalesce adjacent free blocks
}

// ============================================================================
// INITIALIZATION
// ============================================================================

export fn memory_init(memory_size: u64) {
  pmm_init(memory_size)
  vmm_init()
  heap_init()
  
  foundation.serial_write_string("[Memory] Initialized\n")
}
