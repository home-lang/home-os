// home-os VFS - Inode Hash Table
// Optimizes inode lookup from O(n) to O(1) average case using hash table

import "foundation.home" as foundation
import "memory.home" as memory
import "filesystem.home" as filesystem

// ============================================================================
// CONSTANTS
// ============================================================================

const HASH_TABLE_SIZE: u32 = 256  // Power of 2 for efficient modulo
const MAX_INODES: u32 = 1024

// ============================================================================
// DATA STRUCTURES
// ============================================================================

struct InodeHashEntry {
  ino: u32,              // Inode number
  inode_idx: u32,        // Index in inode_table
  next: u32              // Next entry in chain (for collisions)
}

struct InodeHashStats {
  lookups: u64,
  collisions: u64,
  max_chain_length: u32,
  avg_chain_length: u32,
  hash_table_load: u32   // Percentage of buckets used
}

// ============================================================================
// GLOBAL STATE
// ============================================================================

var hash_table: [u32; 256]  // Hash table (stores head of each chain)
var hash_entries: [InodeHashEntry; 1024]  // Collision chains
var entry_count: u32 = 0
var hash_stats: InodeHashStats
var hash_initialized: u32 = 0

// ============================================================================
// HASH FUNCTION
// ============================================================================

fn hash_ino(ino: u32): u32 {
  // Simple but effective hash function
  var hash: u32 = ino

  // Mix the bits (avalanche effect)
  hash = hash ^ (hash >> 16)
  hash = hash * 0x85ebca6b
  hash = hash ^ (hash >> 13)
  hash = hash * 0xc2b2ae35
  hash = hash ^ (hash >> 16)

  return hash % HASH_TABLE_SIZE
}

// Alternative hash functions for different workloads:

fn hash_ino_multiplicative(ino: u32): u32 {
  // Multiplicative hashing (Knuth's method)
  const GOLDEN_RATIO: u32 = 0x9e3779b9  // 2^32 / Ï†
  return (ino * GOLDEN_RATIO) % HASH_TABLE_SIZE
}

fn hash_ino_simple(ino: u32): u32 {
  // Simple modulo (fast but more collisions)
  return ino % HASH_TABLE_SIZE
}

fn hash_ino_xor_shift(ino: u32): u32 {
  // XOR-shift hash
  var hash: u32 = ino
  hash = hash ^ (hash << 13)
  hash = hash ^ (hash >> 17)
  hash = hash ^ (hash << 5)
  return hash % HASH_TABLE_SIZE
}

// ============================================================================
// HASH TABLE OPERATIONS
// ============================================================================

export fn inode_hash_insert(ino: u32, inode_idx: u32): u32 {
  if entry_count >= MAX_INODES {
    return 1  // Table full
  }

  // Find free entry
  var entry_idx: u32 = 0
  while entry_idx < MAX_INODES {
    if hash_entries[entry_idx].ino == 0 {
      break
    }
    entry_idx = entry_idx + 1
  }

  if entry_idx >= MAX_INODES {
    return 1  // No free entries
  }

  // Get hash bucket
  var bucket: u32 = hash_ino(ino)

  // Insert at head of chain
  hash_entries[entry_idx].ino = ino
  hash_entries[entry_idx].inode_idx = inode_idx
  hash_entries[entry_idx].next = hash_table[bucket]

  hash_table[bucket] = entry_idx
  entry_count = entry_count + 1

  // Update collision stats
  if hash_entries[entry_idx].next != 0xFFFFFFFF {
    hash_stats.collisions = hash_stats.collisions + 1
  }

  return 0
}

export fn inode_hash_lookup(ino: u32): u32 {
  hash_stats.lookups = hash_stats.lookups + 1

  var bucket: u32 = hash_ino(ino)
  var entry_idx: u32 = hash_table[bucket]
  var chain_length: u32 = 0

  while entry_idx != 0xFFFFFFFF {
    chain_length = chain_length + 1

    if hash_entries[entry_idx].ino == ino {
      // Found it!
      if chain_length > hash_stats.max_chain_length {
        hash_stats.max_chain_length = chain_length
      }
      return hash_entries[entry_idx].inode_idx
    }

    entry_idx = hash_entries[entry_idx].next
  }

  return 0xFFFFFFFF  // Not found
}

export fn inode_hash_remove(ino: u32): u32 {
  var bucket: u32 = hash_ino(ino)
  var entry_idx: u32 = hash_table[bucket]
  var prev_idx: u32 = 0xFFFFFFFF

  while entry_idx != 0xFFFFFFFF {
    if hash_entries[entry_idx].ino == ino {
      // Found it, remove from chain
      if prev_idx == 0xFFFFFFFF {
        // Head of chain
        hash_table[bucket] = hash_entries[entry_idx].next
      } else {
        // Middle/end of chain
        hash_entries[prev_idx].next = hash_entries[entry_idx].next
      }

      // Mark entry as free
      hash_entries[entry_idx].ino = 0
      hash_entries[entry_idx].inode_idx = 0
      hash_entries[entry_idx].next = 0xFFFFFFFF

      entry_count = entry_count - 1
      return 0  // Removed
    }

    prev_idx = entry_idx
    entry_idx = hash_entries[entry_idx].next
  }

  return 1  // Not found
}

// ============================================================================
// BATCH OPERATIONS
// ============================================================================

export fn inode_hash_rebuild() {
  // Rebuild entire hash table from inode_table
  // Useful after loading from disk or major changes

  foundation.serial_write_string("[Inode Hash] Rebuilding hash table...\n")

  // Clear existing hash table
  var i: u32 = 0
  while i < HASH_TABLE_SIZE {
    hash_table[i] = 0xFFFFFFFF
    i = i + 1
  }

  i = 0
  while i < MAX_INODES {
    hash_entries[i].ino = 0
    hash_entries[i].inode_idx = 0
    hash_entries[i].next = 0xFFFFFFFF
    i = i + 1
  }

  entry_count = 0

  // Scan inode_table and rebuild using filesystem.home exports
  var max_inodes: u32 = filesystem.get_max_inodes()
  var inserted: u32 = 0

  i = 0
  while i < max_inodes {
    var inode_ptr: u64 = filesystem.get_inode_at_index(i)
    if inode_ptr != 0 {
      // Get inode number from the inode structure
      var inode: *filesystem.Inode = @ptrFromInt(inode_ptr)
      var ino: u32 = inode.ino

      if ino != 0 {
        var result: u32 = inode_hash_insert(ino, i)
        if result == 0 {
          inserted = inserted + 1
        }
      }
    }
    i = i + 1
  }

  foundation.serial_write_string("[Inode Hash] Rebuild complete, inserted ")
  foundation.serial_write_u32(inserted)
  foundation.serial_write_string(" inodes\n")
}

export fn inode_hash_clear() {
  var i: u32 = 0
  while i < HASH_TABLE_SIZE {
    hash_table[i] = 0xFFFFFFFF
    i = i + 1
  }

  i = 0
  while i < MAX_INODES {
    hash_entries[i].ino = 0
    hash_entries[i].inode_idx = 0
    hash_entries[i].next = 0xFFFFFFFF
    i = i + 1
  }

  entry_count = 0
  hash_stats.collisions = 0
  hash_stats.max_chain_length = 0
}

// ============================================================================
// STATISTICS & ANALYSIS
// ============================================================================

export fn inode_hash_get_stats(): InodeHashStats {
  // Calculate average chain length
  var total_chain_length: u32 = 0
  var used_buckets: u32 = 0

  var i: u32 = 0
  while i < HASH_TABLE_SIZE {
    if hash_table[i] != 0xFFFFFFFF {
      used_buckets = used_buckets + 1

      // Measure chain length
      var chain_len: u32 = 0
      var entry_idx: u32 = hash_table[i]
      while entry_idx != 0xFFFFFFFF {
        chain_len = chain_len + 1
        entry_idx = hash_entries[entry_idx].next
      }
      total_chain_length = total_chain_length + chain_len
    }
    i = i + 1
  }

  if used_buckets > 0 {
    hash_stats.avg_chain_length = total_chain_length / used_buckets
  }

  hash_stats.hash_table_load = (used_buckets * 100) / HASH_TABLE_SIZE

  return hash_stats
}

export fn inode_hash_print_stats() {
  inode_hash_get_stats()

  foundation.serial_write_string("[Inode Hash Table Stats]\n")
  foundation.serial_write_string("  Total inodes: ")
  foundation.serial_write_u32(entry_count)
  foundation.serial_write_string("\n  Total lookups: ")
  foundation.serial_write_u64(hash_stats.lookups)
  foundation.serial_write_string("\n  Collisions: ")
  foundation.serial_write_u64(hash_stats.collisions)
  foundation.serial_write_string("\n  Max chain length: ")
  foundation.serial_write_u32(hash_stats.max_chain_length)
  foundation.serial_write_string("\n  Avg chain length: ")
  foundation.serial_write_u32(hash_stats.avg_chain_length)
  foundation.serial_write_string("\n  Hash table load: ")
  foundation.serial_write_u32(hash_stats.hash_table_load)
  foundation.serial_write_string("%\n")

  // Performance indicator
  if hash_stats.avg_chain_length <= 2 {
    foundation.serial_write_string("  Performance: Excellent (avg chain <= 2)\n")
  } else if hash_stats.avg_chain_length <= 5 {
    foundation.serial_write_string("  Performance: Good (avg chain <= 5)\n")
  } else {
    foundation.serial_write_string("  Performance: Consider resizing (avg chain > 5)\n")
  }
}

export fn inode_hash_analyze_distribution() {
  foundation.serial_write_string("[Hash Distribution Analysis]\n")

  var empty_buckets: u32 = 0
  var buckets_with_1: u32 = 0
  var buckets_with_2_to_5: u32 = 0
  var buckets_with_6_to_10: u32 = 0
  var buckets_with_10_plus: u32 = 0

  var i: u32 = 0
  while i < HASH_TABLE_SIZE {
    var chain_len: u32 = 0
    var entry_idx: u32 = hash_table[i]

    while entry_idx != 0xFFFFFFFF {
      chain_len = chain_len + 1
      entry_idx = hash_entries[entry_idx].next
    }

    if chain_len == 0 {
      empty_buckets = empty_buckets + 1
    } else if chain_len == 1 {
      buckets_with_1 = buckets_with_1 + 1
    } else if chain_len <= 5 {
      buckets_with_2_to_5 = buckets_with_2_to_5 + 1
    } else if chain_len <= 10 {
      buckets_with_6_to_10 = buckets_with_6_to_10 + 1
    } else {
      buckets_with_10_plus = buckets_with_10_plus + 1
    }

    i = i + 1
  }

  foundation.serial_write_string("  Empty buckets: ")
  foundation.serial_write_u32(empty_buckets)
  foundation.serial_write_string("\n  Buckets with 1 entry: ")
  foundation.serial_write_u32(buckets_with_1)
  foundation.serial_write_string("\n  Buckets with 2-5 entries: ")
  foundation.serial_write_u32(buckets_with_2_to_5)
  foundation.serial_write_string("\n  Buckets with 6-10 entries: ")
  foundation.serial_write_u32(buckets_with_6_to_10)
  foundation.serial_write_string("\n  Buckets with 10+ entries: ")
  foundation.serial_write_u32(buckets_with_10_plus)
  foundation.serial_write_string("\n")
}

// ============================================================================
// PERFORMANCE COMPARISON
// ============================================================================

export fn inode_hash_benchmark_linear_vs_hash() {
  foundation.serial_write_string("[Performance Benchmark: Linear vs Hash]\n")

  // This would compare O(n) linear search vs O(1) hash lookup
  // Useful for demonstrating the optimization benefit

  var test_ino: u32 = 500  // Middle of range

  // Measure hash lookup time
  var hash_start: u64 = foundation.get_timestamp()
  var result1: u32 = inode_hash_lookup(test_ino)
  var hash_end: u64 = foundation.get_timestamp()
  var hash_time: u64 = hash_end - hash_start

  // Measure linear search time (simulated)
  var linear_start: u64 = foundation.get_timestamp()
  var i: u32 = 0
  var result2: u32 = 0xFFFFFFFF
  while i < entry_count {
    if i == result1 {  // Simulate finding it
      result2 = i
      break
    }
    i = i + 1
  }
  var linear_end: u64 = foundation.get_timestamp()
  var linear_time: u64 = linear_end - linear_start

  foundation.serial_write_string("  Hash lookup time: ")
  foundation.serial_write_u64(hash_time)
  foundation.serial_write_string(" cycles\n")
  foundation.serial_write_string("  Linear search time: ")
  foundation.serial_write_u64(linear_time)
  foundation.serial_write_string(" cycles\n")

  if linear_time > 0 {
    var speedup: u64 = linear_time / (hash_time + 1)
    foundation.serial_write_string("  Speedup: ")
    foundation.serial_write_u64(speedup)
    foundation.serial_write_string("x faster\n")
  }
}

// ============================================================================
// INITIALIZATION
// ============================================================================

export fn inode_hash_init() {
  if hash_initialized == 1 { return }

  // Initialize hash table
  var i: u32 = 0
  while i < HASH_TABLE_SIZE {
    hash_table[i] = 0xFFFFFFFF  // Empty bucket marker
    i = i + 1
  }

  // Initialize entries
  i = 0
  while i < MAX_INODES {
    hash_entries[i].ino = 0
    hash_entries[i].inode_idx = 0
    hash_entries[i].next = 0xFFFFFFFF
    i = i + 1
  }

  entry_count = 0
  hash_stats.lookups = 0
  hash_stats.collisions = 0
  hash_stats.max_chain_length = 0
  hash_stats.avg_chain_length = 0
  hash_stats.hash_table_load = 0

  hash_initialized = 1

  foundation.serial_write_string("[Inode Hash] Initialized (256 buckets, O(1) lookup)\n")
}

// ============================================================================
// ADVANCED: DYNAMIC RESIZING (Optional)
// ============================================================================

export fn inode_hash_should_resize(): u32 {
  inode_hash_get_stats()

  // Resize if:
  // 1. Load factor > 75%
  // 2. Average chain length > 5
  if hash_stats.hash_table_load > 75 or hash_stats.avg_chain_length > 5 {
    return 1
  }

  return 0
}

export fn inode_hash_suggest_size(): u32 {
  // Suggest next power of 2 based on entry count
  var suggested: u32 = 256

  if entry_count > 768 {
    suggested = 1024
  } else if entry_count > 384 {
    suggested = 512
  }

  return suggested
}

// ============================================================================
// INTEGRATION WITH FILESYSTEM.HOME
// ============================================================================

export fn inode_get_optimized(ino: u32): u64 {
  // Drop-in replacement for filesystem.inode_get()
  // Uses hash table instead of linear search - O(1) average case

  var inode_idx: u32 = inode_hash_lookup(ino)

  if inode_idx == 0xFFFFFFFF {
    return 0  // Not found
  }

  // Return actual inode pointer from filesystem's inode table
  return filesystem.get_inode_at_index(inode_idx)
}

// ============================================================================
// AUTO-SYNC WITH FILESYSTEM OPERATIONS
// ============================================================================

// Call this after inode_alloc() to add to hash table
export fn inode_hash_on_alloc(ino: u32, inode_idx: u32) {
  inode_hash_insert(ino, inode_idx)
}

// Call this before inode_free() to remove from hash table
export fn inode_hash_on_free(ino: u32) {
  inode_hash_remove(ino)
}

// Batch sync - walk inode table and ensure hash is consistent
export fn inode_hash_sync() {
  var max_inodes: u32 = filesystem.get_max_inodes()
  var synced: u32 = 0
  var added: u32 = 0
  var removed: u32 = 0

  // First pass: ensure all valid inodes are in hash table
  var i: u32 = 0
  while i < max_inodes {
    var inode_ptr: u64 = filesystem.get_inode_at_index(i)
    if inode_ptr != 0 {
      var inode: *filesystem.Inode = @ptrFromInt(inode_ptr)
      var ino: u32 = inode.ino

      if ino != 0 {
        // Check if already in hash table
        var existing_idx: u32 = inode_hash_lookup(ino)
        if existing_idx == 0xFFFFFFFF {
          // Not in hash, add it
          inode_hash_insert(ino, i)
          added = added + 1
        } else if existing_idx != i {
          // In hash but wrong index, update
          inode_hash_remove(ino)
          inode_hash_insert(ino, i)
          synced = synced + 1
        }
      }
    }
    i = i + 1
  }

  // Second pass: remove stale entries from hash table
  i = 0
  while i < MAX_INODES {
    if hash_entries[i].ino != 0 {
      var ino: u32 = hash_entries[i].ino
      var idx: u32 = hash_entries[i].inode_idx

      // Verify inode still exists
      var inode_ptr: u64 = filesystem.get_inode_at_index(idx)
      if inode_ptr == 0 {
        inode_hash_remove(ino)
        removed = removed + 1
      } else {
        var inode: *filesystem.Inode = @ptrFromInt(inode_ptr)
        if inode.ino != ino {
          inode_hash_remove(ino)
          removed = removed + 1
        }
      }
    }
    i = i + 1
  }

  foundation.serial_write_string("[Inode Hash] Sync: ")
  foundation.serial_write_u32(added)
  foundation.serial_write_string(" added, ")
  foundation.serial_write_u32(removed)
  foundation.serial_write_string(" removed, ")
  foundation.serial_write_u32(synced)
  foundation.serial_write_string(" updated\n")
}

// Get inode with fallback to linear search
export fn inode_get_with_fallback(ino: u32): u64 {
  // Try hash table first (O(1))
  var inode_idx: u32 = inode_hash_lookup(ino)

  if inode_idx != 0xFFFFFFFF {
    var inode_ptr: u64 = filesystem.get_inode_at_index(inode_idx)
    if inode_ptr != 0 {
      // Verify it's the right inode
      var inode: *filesystem.Inode = @ptrFromInt(inode_ptr)
      if inode.ino == ino {
        return inode_ptr
      }
    }
    // Hash table was stale, remove entry
    inode_hash_remove(ino)
  }

  // Fall back to linear search
  var max_inodes: u32 = filesystem.get_max_inodes()
  var i: u32 = 0
  while i < max_inodes {
    var inode_ptr: u64 = filesystem.get_inode_at_index(i)
    if inode_ptr != 0 {
      var inode: *filesystem.Inode = @ptrFromInt(inode_ptr)
      if inode.ino == ino {
        // Found it, add to hash for next time
        inode_hash_insert(ino, i)
        return inode_ptr
      }
    }
    i = i + 1
  }

  return 0  // Not found
}
