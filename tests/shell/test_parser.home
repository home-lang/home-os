// HomeOS Shell Parser Test Suite
// Focused tests for quoting, pipelines, redirections, and error handling

const parser = @import("../../apps/shell_parser.home")
const serial = @import("../../kernel/src/drivers/serial.home")

// ============================================================================
// Test Framework
// ============================================================================

var tests_run: u32 = 0
var tests_passed: u32 = 0
var tests_failed: u32 = 0

fn test_start(name: *u8) void {
    serial.write_string("  TEST: ")
    serial.write_string(name)
    serial.write_string(" ... ")
    tests_run += 1
}

fn test_pass() void {
    serial.write_string("PASS\n")
    tests_passed += 1
}

fn test_fail(reason: *u8) void {
    serial.write_string("FAIL: ")
    serial.write_string(reason)
    serial.write_string("\n")
    tests_failed += 1
}

fn assert_eq_u32(expected: u32, actual: u32, msg: *u8) u32 {
    if (expected == actual) return 1
    serial.write_string("Expected ")
    serial.write_u32(expected)
    serial.write_string(" but got ")
    serial.write_u32(actual)
    serial.write_string(" (")
    serial.write_string(msg)
    serial.write_string(")")
    return 0
}

fn assert_str_eq(expected: *u8, actual: *u8, msg: *u8) u32 {
    var i: u32 = 0
    while (expected[i] != 0 or actual[i] != 0) {
        if (expected[i] != actual[i]) {
            serial.write_string("String mismatch (")
            serial.write_string(msg)
            serial.write_string(")")
            return 0
        }
        i += 1
    }
    return 1
}

// ============================================================================
// Quoting Tests
// ============================================================================

fn test_simple_word() void {
    test_start("Simple word")

    var input: [32]u8 = "hello".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 5)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    if (result.token_count != 2) {  // word + EOF
        test_fail("Wrong token count")
        return
    }

    if (result.tokens[0].token_type != parser.TOKEN_WORD) {
        test_fail("Wrong token type")
        return
    }

    if (assert_str_eq("hello", &result.tokens[0].value[0], "value") == 0) {
        test_fail("Wrong value")
        return
    }

    test_pass()
}

fn test_single_quotes() void {
    test_start("Single quotes")

    var input: [32]u8 = "'hello world'".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 13)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    if (result.tokens[0].quoted != 1) {
        test_fail("Not marked as quoted")
        return
    }

    if (assert_str_eq("hello world", &result.tokens[0].value[0], "value") == 0) {
        test_fail("Wrong value")
        return
    }

    test_pass()
}

fn test_double_quotes() void {
    test_start("Double quotes")

    var input: [32]u8 = "\"hello world\"".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 13)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    if (assert_str_eq("hello world", &result.tokens[0].value[0], "value") == 0) {
        test_fail("Wrong value")
        return
    }

    test_pass()
}

fn test_escape_in_double_quotes() void {
    test_start("Escape in double quotes")

    var input: [32]u8 = "\"hello\\\"world\"".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 15)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    // Should have hello"world
    if (assert_str_eq("hello\"world", &result.tokens[0].value[0], "value") == 0) {
        test_fail("Escape not processed")
        return
    }

    test_pass()
}

fn test_unterminated_single_quote() void {
    test_start("Unterminated single quote")

    var input: [32]u8 = "'hello".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 6)

    if (result.error_code != parser.PARSE_ERR_UNTERMINATED_QUOTE) {
        test_fail("Should detect unterminated quote")
        return
    }

    test_pass()
}

fn test_unterminated_double_quote() void {
    test_start("Unterminated double quote")

    var input: [32]u8 = "\"hello".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 6)

    if (result.error_code != parser.PARSE_ERR_UNTERMINATED_QUOTE) {
        test_fail("Should detect unterminated quote")
        return
    }

    test_pass()
}

fn test_mixed_quotes() void {
    test_start("Mixed quotes")

    var input: [64]u8 = "echo 'single' \"double\"".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 23)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    // Should have 3 word tokens + EOF
    if (result.token_count != 4) {
        test_fail("Wrong token count")
        return
    }

    test_pass()
}

fn test_escaped_backslash() void {
    test_start("Escaped backslash")

    var input: [32]u8 = "hello\\\\world".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 12)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    // Should have hello\world
    if (assert_str_eq("hello\\world", &result.tokens[0].value[0], "value") == 0) {
        test_fail("Backslash not escaped")
        return
    }

    test_pass()
}

// ============================================================================
// Pipeline Tests
// ============================================================================

fn test_simple_pipe() void {
    test_start("Simple pipe")

    var input: [64]u8 = "ls | grep foo".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 13)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (parser.shell_get_pipeline_error() != parser.PARSE_OK) {
        test_fail("Pipeline parse failed")
        return
    }

    if (pipeline.stage_count != 2) {
        test_fail("Should have 2 stages")
        return
    }

    test_pass()
}

fn test_multi_pipe() void {
    test_start("Multi-stage pipe")

    var input: [64]u8 = "cat file | grep pat | sort | head".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 33)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (pipeline.stage_count != 4) {
        test_fail("Should have 4 stages")
        return
    }

    test_pass()
}

fn test_empty_pipe_start() void {
    test_start("Empty pipe at start")

    var input: [32]u8 = "| ls".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 4)

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (parser.shell_get_pipeline_error() != parser.PARSE_ERR_EMPTY_PIPE) {
        test_fail("Should detect empty pipe")
        return
    }

    test_pass()
}

fn test_empty_pipe_middle() void {
    test_start("Empty pipe in middle")

    var input: [32]u8 = "ls | | grep".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 11)

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (parser.shell_get_pipeline_error() != parser.PARSE_ERR_EMPTY_PIPE) {
        test_fail("Should detect empty pipe")
        return
    }

    test_pass()
}

fn test_empty_pipe_end() void {
    test_start("Empty pipe at end")

    var input: [32]u8 = "ls |".*

    if (parser.shell_validate_command(&input[0], 4) != parser.PARSE_ERR_EMPTY_PIPE) {
        test_fail("Should detect empty pipe at end")
        return
    }

    test_pass()
}

// ============================================================================
// Redirection Tests
// ============================================================================

fn test_output_redirect() void {
    test_start("Output redirect")

    var input: [64]u8 = "echo hello > file.txt".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 21)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (pipeline.stage_count != 1) {
        test_fail("Should have 1 stage")
        return
    }

    if (pipeline.commands[0].redir_count != 1) {
        test_fail("Should have 1 redirection")
        return
    }

    if (pipeline.commands[0].redirections[0].redir_type != parser.TOKEN_REDIR_OUT) {
        test_fail("Wrong redirect type")
        return
    }

    test_pass()
}

fn test_append_redirect() void {
    test_start("Append redirect")

    var input: [64]u8 = "echo hello >> file.txt".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 22)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (pipeline.commands[0].redirections[0].redir_type != parser.TOKEN_REDIR_APPEND) {
        test_fail("Wrong redirect type")
        return
    }

    test_pass()
}

fn test_input_redirect() void {
    test_start("Input redirect")

    var input: [64]u8 = "sort < unsorted.txt".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 19)

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (pipeline.commands[0].redirections[0].redir_type != parser.TOKEN_REDIR_IN) {
        test_fail("Wrong redirect type")
        return
    }

    if (pipeline.commands[0].redirections[0].fd != 0) {
        test_fail("Should redirect stdin")
        return
    }

    test_pass()
}

fn test_combined_redirects() void {
    test_start("Combined redirects")

    var input: [64]u8 = "sort < in.txt > out.txt".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 23)

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (pipeline.commands[0].redir_count != 2) {
        test_fail("Should have 2 redirections")
        return
    }

    test_pass()
}

fn test_missing_redirect_target() void {
    test_start("Missing redirect target")

    var input: [32]u8 = "echo >".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 6)

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (parser.shell_get_pipeline_error() != parser.PARSE_ERR_INVALID_REDIR) {
        test_fail("Should detect missing target")
        return
    }

    test_pass()
}

// ============================================================================
// Background Tests
// ============================================================================

fn test_background_job() void {
    test_start("Background job")

    var input: [32]u8 = "sleep 10 &".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 10)

    var pipeline: *parser.Pipeline = parser.shell_parse_pipeline(result)

    if (pipeline.commands[0].background != 1) {
        test_fail("Should be marked as background")
        return
    }

    test_pass()
}

// ============================================================================
// Operator Tests
// ============================================================================

fn test_and_operator() void {
    test_start("AND operator")

    var input: [64]u8 = "mkdir foo && cd foo".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 19)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    // Check for AND token
    var found_and: u32 = 0
    var i: u32 = 0
    while (i < result.token_count) {
        if (result.tokens[i].token_type == parser.TOKEN_AND) {
            found_and = 1
            break
        }
        i += 1
    }

    if (found_and == 0) {
        test_fail("AND token not found")
        return
    }

    test_pass()
}

fn test_or_operator() void {
    test_start("OR operator")

    var input: [64]u8 = "false || echo fallback".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 22)

    // Check for OR token
    var found_or: u32 = 0
    var i: u32 = 0
    while (i < result.token_count) {
        if (result.tokens[i].token_type == parser.TOKEN_OR) {
            found_or = 1
            break
        }
        i += 1
    }

    if (found_or == 0) {
        test_fail("OR token not found")
        return
    }

    test_pass()
}

fn test_semicolon() void {
    test_start("Semicolon separator")

    var input: [64]u8 = "echo one; echo two".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 18)

    var found_semi: u32 = 0
    var i: u32 = 0
    while (i < result.token_count) {
        if (result.tokens[i].token_type == parser.TOKEN_SEMICOLON) {
            found_semi = 1
            break
        }
        i += 1
    }

    if (found_semi == 0) {
        test_fail("SEMICOLON token not found")
        return
    }

    test_pass()
}

// ============================================================================
// Comment Tests
// ============================================================================

fn test_comment() void {
    test_start("Comment handling")

    var input: [64]u8 = "echo hello # this is a comment".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 30)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    // Should only have "echo" and "hello" + EOF
    if (result.token_count != 3) {
        test_fail("Comment not ignored")
        return
    }

    test_pass()
}

// ============================================================================
// Edge Case Tests
// ============================================================================

fn test_empty_input() void {
    test_start("Empty input")

    var input: [8]u8 = "".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 0)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Should handle empty input")
        return
    }

    test_pass()
}

fn test_whitespace_only() void {
    test_start("Whitespace only")

    var input: [16]u8 = "   \t  \t  ".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 9)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Should handle whitespace")
        return
    }

    // Should only have EOF token
    if (result.token_count != 1 or result.tokens[0].token_type != parser.TOKEN_EOF) {
        test_fail("Should be empty except EOF")
        return
    }

    test_pass()
}

fn test_long_token() void {
    test_start("Long token (near limit)")

    // Create a token near the max length
    var input: [1030]u8 = undefined
    var i: u32 = 0
    while (i < 1020) {
        input[i] = 'a'
        i += 1
    }
    input[1020] = 0

    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 1020)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Should handle long tokens")
        return
    }

    test_pass()
}

fn test_adjacent_quotes() void {
    test_start("Adjacent quotes")

    var input: [32]u8 = "'hello'\"world\"".*
    var result: *parser.ParseResult = parser.shell_tokenize(&input[0], 14)

    if (result.error_code != parser.PARSE_OK) {
        test_fail("Tokenize failed")
        return
    }

    // Should be a single token with value "helloworld"
    if (result.token_count != 2) {
        test_fail("Should be single token + EOF")
        return
    }

    if (assert_str_eq("helloworld", &result.tokens[0].value[0], "value") == 0) {
        test_fail("Quotes not concatenated")
        return
    }

    test_pass()
}

// ============================================================================
// Test Runner
// ============================================================================

export fn run_parser_tests() u32 {
    serial.write_string("\n")
    serial.write_string("=========================================\n")
    serial.write_string("   HomeOS Shell Parser Test Suite\n")
    serial.write_string("=========================================\n\n")

    tests_run = 0
    tests_passed = 0
    tests_failed = 0

    // Quoting tests
    serial.write_string("Quoting Tests:\n")
    test_simple_word()
    test_single_quotes()
    test_double_quotes()
    test_escape_in_double_quotes()
    test_unterminated_single_quote()
    test_unterminated_double_quote()
    test_mixed_quotes()
    test_escaped_backslash()

    // Pipeline tests
    serial.write_string("\nPipeline Tests:\n")
    test_simple_pipe()
    test_multi_pipe()
    test_empty_pipe_start()
    test_empty_pipe_middle()
    test_empty_pipe_end()

    // Redirection tests
    serial.write_string("\nRedirection Tests:\n")
    test_output_redirect()
    test_append_redirect()
    test_input_redirect()
    test_combined_redirects()
    test_missing_redirect_target()

    // Background tests
    serial.write_string("\nBackground Tests:\n")
    test_background_job()

    // Operator tests
    serial.write_string("\nOperator Tests:\n")
    test_and_operator()
    test_or_operator()
    test_semicolon()

    // Comment tests
    serial.write_string("\nComment Tests:\n")
    test_comment()

    // Edge case tests
    serial.write_string("\nEdge Case Tests:\n")
    test_empty_input()
    test_whitespace_only()
    test_long_token()
    test_adjacent_quotes()

    // Summary
    serial.write_string("\n=========================================\n")
    serial.write_string("Results: ")
    serial.write_u32(tests_passed)
    serial.write_string("/")
    serial.write_u32(tests_run)
    serial.write_string(" passed")

    if (tests_failed > 0) {
        serial.write_string(" (")
        serial.write_u32(tests_failed)
        serial.write_string(" FAILED)")
    }

    serial.write_string("\n=========================================\n\n")

    return tests_failed
}

export fn main() u32 {
    return run_parser_tests()
}

